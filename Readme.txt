Deep Learning May 2022

Team 1
1) Tan Jing Jie (Leader)
2) Ng Jan Hui
3) Sia Ken Yen

This file contain:
1) Final Report (in PDF)
2) SourceCode (in ipynb)
3) extract (in ipynb)
4) Supplementary material: AmericanSignLanguageRecognitionSimulationVideo (in txt, content: https://youtu.be/HDJXluPlGRM)

Objectives
1) To design a convolutional neural network (CNN) architecture with competitive performance.
2) To investigate the relationship between reduction of color channels and model predictive performance.
3) To investigate the effects of different regularization methods on model performance.
4) To investigate the performance of famous CNNs when being reimplemented.


Dataset Used
American Sign Language Dataset
Link: https://www.kaggle.com/datasets/grassknoted/asl-alphabet


Google Drive Folder Link (Include colab notebook)
Link: https://drive.google.com/drive/folders/1-yB27djKv71A2JKVl_PjFQrcxhOxyhZ6?usp=sharing


Simulation Video
Link 1: https://drive.google.com/file/d/1WjJXtZfSEX83kQFmNUZ3Rnd__eZmhMek/view?usp=sharing
or
Link 2: https://youtu.be/HDJXluPlGRM


How to use
1) Download the dataset from the link provided
2) Unzip it and place the extract.ipynb on parent directory (use pip install package if needed)
3) Upload the extracted dataset into Google Colab
4) Put the SourceCode.ipynb into Google Colab at the dataset parent directory
5) Execute the first block of SourceCode.ipynb file to mount the Google Drive
6) Execute the block of code for dataset exploration, training, testing, evaluation and visualisation.
6) The last part of the code in SourceCode.ipynb is simulation, execute it and allow brownser to access the camera.
7) Enjoy it!

If there any enquiry, please feel free to contact Tan Jing Jie. I can be reached as below:
1) By phone, +6011-38100852
2) By email / Microsoft Team, tanjingjie@1utar.my